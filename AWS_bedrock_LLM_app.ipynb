{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Bedrock LLM Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Amazon Bedrock, start by signing up for an AWS account(https://aws.amazon.com/aispl/registration-confirmation/). Once you have successfully logged in, go to Amazon Bedrock Console and get started. Keep in mind that, by default, users do not have model access. \n",
    "\n",
    "\n",
    "You should request access from Model Access Page (https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess). For this application, we’re going to use “Titan Text G1 Express” model by Amazon. Unfortunately, there is no free tier for Amazon Bedrock, therefore, you might need to provide payment information at this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "AWS_KEY=os.getenv(\"AWS_KEY\")\n",
    "AWS_SECRET_KEY=os.getenv(\"AWS_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setting Up the Python Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Setup the Bedrock runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(profile_name='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the boto3 object for bedrock\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name='bedrock', \n",
    "region_name='us-east-1', \n",
    "aws_access_key_id=AWS_KEY, \n",
    "aws_secret_access_key=AWS_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write command to get all the modelId for the claude models that are available through your account\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic.claude-instant-v1:2:100k\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v2:0:18k\n",
      "anthropic.claude-v2:0:100k\n",
      "anthropic.claude-v2:1:18k\n",
      "anthropic.claude-v2:1:200k\n",
      "anthropic.claude-v2:1\n",
      "anthropic.claude-v2\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0\n",
      "anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.list_foundation_models(byProvider=\"anthropic\")\n",
    "\n",
    "for summary in response[\"modelSummaries\"]:\n",
    "    print(summary[\"modelId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install Boto3: Boto3 is the Amazon Web Services (AWS) SDK for Python. It allows Python developers to write software that makes use of all AWS services like Amazon Bedrock, Amazon S3 and Amazon EC2. Install it using pip.\n",
    "\n",
    "* AWS Credentials: Ensure you have your AWS access key (AWS_KEY) and AWS secret access key (AWS_SECRET_KEY). These are necessary for authentication with AWS services.\n",
    "\n",
    "* Import these libraries in your Python file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up parameters to access Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelId obtained from printing out modelIds in previous step\n",
    "modelId = 'anthropic.claude-v2:1'\n",
    "\n",
    "### parameters for the LLM to control text-generation\n",
    "# temperature increases randomness as it increases\n",
    "temperature = 0.5\n",
    "# top_p increases more word choice as it increases\n",
    "top_p = 1\n",
    "# maximum number of tokens to generate in the output\n",
    "max_tokens_to_generate = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have set up the parameters it is time to create our prompts.\n",
    "\n",
    "Claude takes both a system prompt, and a list of messages. The format should be like below. Note: the order of the messages is important and must start with the user role, and alternate with the assistant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"All your responses should be in Haiku form\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, world, tell me a funny poem\"}, \n",
    "            {\"role\": \"assistant\", \"content\": \"Here is a haiku poem for you:\\n\\nLaughing out loud\\nAt silly jokes and stories\\nBringing joyful smiles\"},\n",
    "            {\"role\": \"user\", \"content\": \"I don't want to smile\"}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the variables to call the Bedrock service\n",
    "Create a new boto3 object for bedrock-runtime. Note: this is different from the boto3 object above that uses bedrock NOT bedrock-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', \n",
    "region_name='us-east-1', \n",
    "aws_access_key_id=AWS_KEY, \n",
    "aws_secret_access_key=AWS_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare your JSON body to send to bedrock. We have created all the variables before, and additionally we pass the anthropic version. Note: there are other parameters available through Bedrock as well, give the docs a read for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "            \"messages\": messages,\n",
    "            \"system\": system_prompt,\n",
    "            \"max_tokens\": max_tokens_to_generate,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Send data to Bedrock\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=\"application/json\", contentType=\"application/json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Read the generated data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': 'I understand, my friend\\nSmiles can be tiring'}]\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "result = response_body.get('content', '')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Python Script\n",
    "##### The full script looks as follows. Remember to execute the printing modelID part first before fully running it all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic.claude-instant-v1:2:100k\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v2:0:18k\n",
      "anthropic.claude-v2:0:100k\n",
      "anthropic.claude-v2:1:18k\n",
      "anthropic.claude-v2:1:200k\n",
      "anthropic.claude-v2:1\n",
      "anthropic.claude-v2\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "anthropic.claude-3-sonnet-20240229-v1:0\n",
      "anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "anthropic.claude-3-haiku-20240307-v1:0\n",
      "[{'type': 'text', 'text': 'I understand, friend\\nNot always in mood for mirth\\nAnother time, maybe'}]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "AWS_KEY=os.getenv(\"AWS_KEY\")\n",
    "AWS_SECRET_KEY=os.getenv(\"AWS_SECRET_KEY\")\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock', \n",
    "region_name='us-east-1', \n",
    "aws_access_key_id=AWS_KEY, \n",
    "aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "response = bedrock.list_foundation_models(byProvider=\"anthropic\")\n",
    "\n",
    "for summary in response[\"modelSummaries\"]:\n",
    "    print(summary[\"modelId\"])\n",
    "\n",
    "# modelId obtained from printing out modelIds in previous step\n",
    "modelId = 'anthropic.claude-v2:1'\n",
    "\n",
    "### parameters for the LLM to control text-generation\n",
    "# temperature increases randomness as it increases\n",
    "temperature = 0.5\n",
    "# top_p increases more word choice as it increases\n",
    "top_p = 1\n",
    "# maximum number of tokens togenerate in the output\n",
    "max_tokens_to_generate = 250\n",
    "\n",
    "system_prompt = \"All your responses should be in Haiku form\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, world, tell me a funny poem\"}, \n",
    "            {\"role\": \"assistant\", \"content\": \"Here is a haiku poem for you:\\n\\nLaughing out loud\\nAt silly jokes and stories\\nBringing joyful smiles\"},\n",
    "            {\"role\": \"user\", \"content\": \"I don't want to smile\"}]\n",
    "\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', \n",
    "region_name='us-east-1', \n",
    "aws_access_key_id=AWS_KEY, \n",
    "aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "body = json.dumps({\n",
    "            \"messages\": messages,\n",
    "            \"system\": system_prompt,\n",
    "            \"max_tokens\": max_tokens_to_generate,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "})\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=\"application/json\", contentType=\"application/json\")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "result = response_body.get('content', '')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
